{
    "prefix": "sentencepiece",
    "body": [
        "import sentencepiece as spm",
        "spm.SentencePieceTrainer.train(input='your.txt', model_prefix='spm', vocab_size=20000, user_defined_symbols=[])",
        "tokenizer = spm.SentencePieceProcessor(model_file='m.model')",
        "tokenizer.encode(\"text\")"
    ],
    "description": "usage of sentencepiece"
}